### 老师总结笔记

```
1、zk
	watch监听机制。
		谁监听谁?  客户端监听服务端
		监听什么事？监听zk目录树znode的变化
		
		监听步骤。 设置  执行  触发通知
		zk监听特点
			先注册再触发
			一次性
			异步通知
2、zk的典型应用

	数据发布、订阅
		核心：集中配置管理 支持实时动态更新
		
	为其他软件选举服务
		核心：找出唯一  找出新的唯一
	
	kafka hbase hadoop——ha 都利用了zk的这些功能。
	
3、认识hadoop 搭建hadoop集群
	hadoop狭义 广义之分
	hadoop起源
		Nutch 全网搜索  面临：海量数据存储（网页）、海量数据的计算（倒排索引）
		Google3篇论文
	hadoop优点
		通用性---- 精准区分了技术和业务问题  hadoop实现了技术 用户负责实现业务
		
	hadoop发行版本、架构
		官方社区版
			apache社区
		商业发行版
			Cloudera---CDH
			阿里、腾讯等封装的版本
		1.x  2.x  3.x	
	
	hadoop核心组件
		hdfs	
			解决了海量数据存储问题  分布式存储系统
		mapreduce
			解决了海量数据的计算问题  分布式计算框架
		yarn
			解决了分布式环境资源的管理 分配 调度问题
			
		
	hadoop集群,都是标准的主从架构集群
		hdfs
			namenode(NN) datanode(DN) secondarynamenode(SNN)
		yarn
			resourcemanager(RM)  nodemanager(NM)
			
	hadoop搭建  仔细！！！！！！！
		为什么要进行源码编译？
			没有提供源码
			你想自己修改源码
			适配操作系统环境
			
		为什么要进行集群规划？
			合理分配软件和硬件之间关系
			
	hadoop namenod format 初始化
		一次 首次启动之前
		在node1 namenode所在的机器执行
		
		
	hadoop web UI页面
		hdfs:	namenode所在机器的ip:9870
		yarn:	resourcemanager所在机器的ip:8088
		
	辅助功能
		jobhistory服务
			历史作业信息保存 日志聚集管理
			本服务需要自己单独手动启动 关闭
		hdfs垃圾桶
			类似windows回收站
Hadoop HDFS

1、HDFS
   首先是文件系统  存储文件数据的
   其次才是分布式特性 意味着不是单机存储
   
   HDFS是整个大数据最底层的框架 
   实际中操作：提供数据存储服务 给其他计算引擎提供读写的路径。

2、HDFS核心属性
	主从架构
		NN 管理元数据
		DN 管理数据（数据块block）
		SNN 辅助NN管理元数据
		
	分块存储
		block size=128M(134217728)   hadoop 2.0 64M
		不足128 实际多大这个块就多大
		
	副本机制
		最终3副本机制  1+2=3
		默认3副本策略
			1优先本地 否则随机
			2不同于第一个副本所在机架其他机架
			3和第二个相同机架但是不同节点
		运维：机架感知
			
		不满足条件：策略降级	
			1优先本地 否则随机
			其他副本随机
	
	元数据记录
		描述数据的数据
		文件系统：
			文件自身属性
			文件数据块的位置信息
	
	namespace
		命名空间 名称空间
		描述了一种结构：层次感的结构。  目录树有没有层次感？
	
	一次写入多次读取模型
		设计目标 延迟高 不支持修改操作 
	
3、HDFS shell操作
	命令行可以操作不同的文件系统  具体操作的谁取决于什么？
		写地址协议 如果写协议 以协议为准
		如果没有写 以配置参数值为准
	在上传 下载中涉及一个概念：本地文件系统？这个本地怎么理解。
		客户端的本地的linux系统
		客户端又在哪台机器上？
			你作为用户 在哪台机器敲命令 写代码 这台机器就是客户端机器。
			
			
4、HDFS工作机制【重要！！！！！！！！】			
	NN DN角色职责
		data metadata的区别
	
	【作业：根据课堂画图，将图片版的流程转换成为文字版的流程 能够顺利的叙述出来】
	上传文件流程（写流程）
		pipeline管道上传
		ack应答响应机制
		3副本策略
		数据是以packet包发送的
		
		上传的时候是一个block 一个block上传
		
	下载文件流程（读流程）
		分批获取副本的位置信息
		副本位置信息是排序好的
			近的靠前【近是什么近？ 空间距离远近？网络拓扑中的远近？】
			健康状态好的靠前
	
	NN DN之间的通信机制
		心跳机制
			3s 报活
		
		数据块汇报机制
			6小时 持有数据块情况
			

5、面试题目：遇到小文件多的场景，如何处理？	
	从存储角度来分析
		问题：
			小文件的元数据信息占内存  磁盘压力不大 内存压力大
		解决方案：合并
			上传之前合并
				使用Python java等编程语言合并
			上传之中合并
				appendToFile追加合并
			上传之后合并
				archive归档合并
			
	从计算的角度来分析

6、安全模式
	特点：
		文件系统保护状态 只读不能写
	
	自动进入离开的条件
		hdfs启动之后就会立即进入
		数据块汇报比例 0.999
		持续30s
		
	手动进入离开的用处
		集群升级维护
	
	启示	
		hdfs启动之后 必须等待安全模式结束 文件系统服务才是正常且可用的

7、HDFS的元数据管理
	
	元数据分类？
		文件自身属性
		文件数据块位置
		
	谁来管理元数据？
		nameNode
		
	元数据存储在哪里？
		内存中
			最新最全的  不安全
		磁盘上
			持久化文件 fsimage 镜像文件
			编辑日志  edits log 
1、HDFS SNN
	定位
		NN主角色的辅助角色  NN秘书角色
	职责
		帮助NN合并磁盘上元数据文件  fsimage+edits 
		
		 fsimage不旧 edits不大 NN性能不受影响
		 
	注意事项
		snn绝不是nn备份
		snn尽量不要和nn部署在一台机器  都是内存大户
		合并元数据的过程叫做checkpoint
			1小时
			100w事务操作
			
2、HDFS MapReduce
	
	背后思想：先分再合 分而治之
		具体：
			map分
				把复杂的拆分成若干个小的 为什么拆分？  期许可以并行操作提高效率。
				前提：可以分  分完之后没有依赖。
				
			reduce合
				把map的局部小结果合并成为最终结果
		结合一些生活中的例子感受。		

	hadoop设计构思
		a mr是用来处理大数据  小数据能处理但是没必要
		b mr封装了两个模型 函数式编程  
			map 映射
			reduce 减少
		c 统一封装底层框架  用户负责业务 mr负责技术
		
	mapreduce概念 进程 约束
		分布式程序
		进程种类3个
			maptask
			reducetask
			MrAPPMaster
		约束：只能一个mapper阶段+一个reducer阶段	
		
	官方示例
		如何提交mr程序到yarn上执行。
			hadoop jar|yarn jar xxxxxxxx.jar 参数...
			
		mapreduce支持多种编程语言编写业务代码
			不管哪种编程语言 都不用写了
			因为MapReduce退居二线了
			
			hive sql---->mapreduce---->处理数据
	
	MapReduce工作机制		
		
		MR的输入和输出
			数据都是以kv键值对形式存在
			默认输入TextInputFormat
				一行一行读取数据
				指向文件 处理文件
				执行文件夹 处理文件夹下的所有文件
			默认输出TextOutputFormat
				输出目录不能提前存在
				
		
		map阶段执行流程
			1、maptask并行度
				逻辑切片机制  split size= block size =128M
			2、TextInputFormat	
				一行一行读取数据
				返回k:起始位置偏移量 v:这行内容【关注重点】
			3、map阶段业务代码处理

			4、partition分区
			
			5、缓存区 100M
				减少磁盘内存的IO次数
			6、spill 
				达到0.8比例 触发溢出操作
			7、sort排序 Combiner规约
				key的字典序
			8、merge
				将所有溢出文件合并成为一个完整的文件  过程中还会sort排序
				
				
		reduce阶段执行流程
			1、copy 
				主动拉取数据属于自己处理的数据
			
			2、merge 合并
			
			3、sort排序 key字典序
			
			4、grouping 分组 key相同的分为一组
			   分好的组构造新的键值对
			
		    5、reduce阶段业务代码处理
			
			6、默认输出TextOutputFormat
				写入指定的目录
				
----------------------------------------------------------------------------

面试题目：遇到小文件多的场景，如何处理？	
	从存储角度（HDFS）来分析
		问题：
			小文件的元数据信息占内存  磁盘压力不大 内存压力大
		解决方案：合并
			上传之前合并
				使用Python java等编程语言合并
			上传之中合并
				appendToFile追加合并
			上传之后合并
				archive归档合并
			
	从计算的角度（MapReduce）来分析
		问题：一个文件哪怕再小 本身也是一个块  一个块对应着一个切片 一个切片就启动一个maptask
		
		就会导致多少个小文件就启动多少个maptask来处理 而每个maptask都处理一点点数据 效率不高		
		
		因为maptask是进程级别的 创建 启动  销毁都需要时间精力 成本高。
		
		解决方案：合并

```

